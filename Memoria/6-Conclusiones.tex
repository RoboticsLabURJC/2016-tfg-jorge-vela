\chapter{Conclusiones}\label{cap.conclusiones}

\hspace{1cm} Para finalizar, hay que realizar una evaluaci\'on del trabajo realizado, lo aprendido durante este periodo y los objetivos cumplidos. En un primer aspecto, podemos decir que el trabajo ha sido satisfactorio, se ha conseguido un algoritmo que desarrolle un despegue-b\'usqueda-aterriza como se deseaba en un primer momento, adem\'as que para llegar a ello se han superado distintos retos que han ido surgiendo a lo largo de su desarrollo.

\begin{itemize}
\item{Percepci\'on:} Se ha conseguido realizar un filtro de color para poder aislar los objetos interesantes del resto. Este objetivo se ha conseguido, trabajando principalmente con la librer\'ia OpenCV como hemos visto en la secci\'on \ref{sec:BibliotecaOpenCV} . Destacar que en el simulador esto fue m\'as sencillo debido a la nitidez de los colores y que en el drone real llev\'o m\'as trabajo. Adem\'as se han tenido que hacer diversas pruebas debido a los distintos lugares donde se probaba el drone y la diferencia de colores que hab\'ia debido a la luminosidad, pero al final se consigui\'o un buen filtro, que con ayuda de los operadores morfol\'ogicos (erosi\'on, dilataci\'on, cierre y apertura), nos permit\'ian obtener una imagen de fondo negro y los objetos de los colores deseados en primer plano. %Estas diferencias se pueden observar en las secci\'on \ref{sec:BibliotecaOpenCV} , donde se muestran im\'agenes de la percepci\'on con el drone real y con el simulador.

\hspace{1cm} Una vez obten\'iamos los objetos de los colores deseados, ver si \'estos eran los objetos que quer\'iamos o no. Por una parte, se miraba el \'area que ten\'ian las figuras, y en caso de no llegar a un tamaño predeterminado, \'estas se descartaban como posibles objetos. Por otro lado, nos apoyamos en la forma de la baliza, pues los cuatro cuadrantes que la compon\'ian formaban una cruceta en su centro, la cual era la que se trataba de detectar, por lo que no se depend\'ia s\'olo de unos colores determinados, sino tambi\'en de una figura. 


\item{Control:} Se ha obtenido un comportamiento con tres fases principales:
	\begin{itemize}
		\item{Despegue: } Al despegar, el drone detecta una baliza sobre la que situarse y se estabiliza sobre \'esta, para obtener de esta forma un despegue controlado.
		\item{B\'usqueda: } En esta fase el algoritmo se desplaza en forma de elipse, recorriendo as\'i la zona. Una vez que detecta un posible objeto trata de centrarse sobre \'este.
		\item{Aterrizaje: } Para finalizar, una vez se ha detectado la baliza y se ha centrado sobre ella, el drone comienza a descender, y una vez la baliza tiene un area determinado se env\'ia la opci\'onde aterrizar, terminando as\'i el drone sobre la baliza.
	\end{itemize}
	

\hspace{1cm} En esta parte, a partir de la percepci\'on, se han tenido que ajustar las velocidades, dependiendo si la prueba era para el drone real o para la simulaci\'on, como se ha contado en la secci\'on \ref{sec.control} . Los ejemplos del control del algoritmo se pueden ver en las distintas secciones del cap\'itulo \ref{cap.experimentos} , destacando que el algoritmo completo se encuentra en la secci\'on \ref{sec.algoritmocompleto} , tanto para el drone real como para la simulaci\'on. 

\item{Validaci\'on experimental:} Cada parte del experimento se ha evaluado por separado a lo largo de \'este, haciendo distintas pruebas para la detecci\'on de balizas, as\'i como el control del drone una vez se detectaban \'estas. Estas pruebas pueden verse a lo largo del cap\'itulo \ref{cap.experimentos} , pero muchos de los avances y cambios que se han dado durante el desarrollo est\'an disponibles en la wiki oficial del proyecto, indicada en el capitulo \ref{cap.Objetivos} . A\'un con todo, destacar que trabajar en el drone real ha sido mucho m\'as costoso de lo esperado,sobre todo para el control de velocidades, pues cualquier cambio pequeño en un valor supon\'ia gran cambio en la realidad. Todo esto tambi\'en fue importante para ver la diferenc\'ia que hay cuando tienes s\'olo un control proporcional y despu\'es le añades la componente derivativa. 
		
\end{itemize}

\hspace{1cm} Las distintas pruebas y los avances que se han ido dando durante el desarrollo, se han ido validando y est\'an disponibles en la wiki oficial del proyecto:\\
\underline{\url{http://jderobot.org/Jvela-tfg}}

\hspace{1cm} Por otro lado, mirando los proyectos anteriores a \'este en los que hab\'ia trabajado RoboticsLabs URJC con drones, podemos ver que se ha conseguido algo diferente, ya que en este caso hemos conseguido que un drone navege de forma aut\'onoma gui\'andose por las balizas de color, consiguiendo que vaya de un punto a otro. 


\section{L\'ineas futuras}

\hspace{1cm}Es importante destacar que estos campo de la rob\'otica y la visi\'on se est\'a produciendo un importante crecimiento, y añadiendo lo aprendido en el trabajo y como se puede trabajar en \'el creo que ser\'ia interesante continuar la l\'inea de este proyecto para continuar con el desarrollo y aprendizaje de estas t\'ecnicas. Algunas aplicaciones podrian ser las siguientes.

\begin{itemize}
\item 1ª Probar en exteriores con otro drone diferente, el 3DRSolo drone.
\item 2ª Probar trayectorias m\'as lejanas donde la parte intermedia vaya recurriendo puntos GPS, y s\'olo en la parte final, ya cerca de las coordenadas del destino se active la b\'usqueda visual de la baliza de aterrizaje y el propio aterrizaje.
\item 3ª Incorporar autolocalizaci\'on visual al drone para elaborar una estrategia de b\'usqueda m\'as elaborada y de mayor amplitud.
\end{itemize}

